{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9555b1e2",
   "metadata": {},
   "source": [
    "### Part 3: Create the Search Agent\n",
    "\n",
    "Now that we've vectorized our health plan documents and created an index, we can build a Search Agent with Microsoft Agent Framework. This agent will leverage the Azure AI Search index to retrieve relevant information from your health plan documents in response to user queries. In this section, you'll:\n",
    "- Connect your code to the Azure AI Search index you created earlier\n",
    "- Define and configure a search agent with the appropriate tools and resources\n",
    "- Interact with the agent to perform intelligent, context-aware document retrieval\n",
    "\n",
    "This hands-on exercise demonstrates how retrieval-augmented generation (RAG) can be implemented programmatically, enabling your agent to provide accurate, document-grounded answers using Azure AI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "# uv add the following:\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Your existing configuration\n",
    "deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"INDEX_NAME\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528aa012",
   "metadata": {},
   "source": [
    "For the following exercise, make sure to add the following environment variables to your .env file:\n",
    "\n",
    "```python\n",
    "AZURE_SEARCH_ENDPOINT=https://<search-service-name>.search.windows.net\n",
    "INDEX_NAME=<index-name>-index\n",
    "SEARCH_API_KEY=<search-service-key>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb8dad",
   "metadata": {},
   "source": [
    "You’re creating two clients:\n",
    "\n",
    "- AzureOpenAIChatClient connects to your Azure OpenAI deployment using the endpoint, API key, version, and deployment name so you can send prompts to the model.\n",
    "- SearchClient connects to your Azure AI Search index using its endpoint, index name, and key, allowing you to retrieve relevant documents.\n",
    "\n",
    "Together, these enable a RAG workflow: fetch context from search, then pass it to the model for grounded answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2183358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client using API key\n",
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    deployment_name=deployment\n",
    ")\n",
    "\n",
    "# Initialize search client with correct credentials\n",
    "search_client = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a563aab",
   "metadata": {},
   "source": [
    "The `AzureAISearchTool` wrapper that turns your SearchClient into a callable “tool” for an agent. It’s initialized with an existing Azure AI Search SearchClient. \n",
    "\n",
    "The search(query, top) method runs a semantic search against your index, collects each hit’s chunk content and @search.score, and returns them as a JSON-formatted string for easy injection into a prompt. If Azure Search returns an error (HttpResponseError), it prints basic diagnostics and returns a JSON error payload instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureAISearchTool:\n",
    "    \"\"\"Function tool to search Azure AI Search index\"\"\"\n",
    "   \n",
    "    def __init__(self, search_client: SearchClient):\n",
    "        self.search_client = search_client\n",
    "   \n",
    "    def search(self, query: str, top: int = 5) -> str:\n",
    "        \"\"\"\n",
    "        Search the Azure AI Search index for relevant documents\n",
    "       \n",
    "        Args:\n",
    "            query: The search query about lighting technology advancements or related topics\n",
    "            top: Number of results to return (default 5)\n",
    "       \n",
    "        Returns:\n",
    "            JSON string containing the search results with chunks and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.search_client.search(\n",
    "                query,\n",
    "                top=top,\n",
    "                query_type=\"semantic\"\n",
    "            )\n",
    "           \n",
    "            documents = []\n",
    "            for doc in results:\n",
    "                documents.append({\n",
    "                    \"chunk\": doc.get('chunk', ''),\n",
    "                    \"score\": doc.get('@search.score', 0)\n",
    "                })\n",
    "           \n",
    "            # Return formatted results\n",
    "            return json.dumps(documents, indent=2)\n",
    "           \n",
    "        except HttpResponseError as e:\n",
    "            print(\"HTTP status:\", e.status_code if hasattr(e, \"status_code\") else \"N/A\")\n",
    "            if e.response is not None:\n",
    "                try:\n",
    "                    print(\"Response text:\", e.response.text())\n",
    "                except Exception:\n",
    "                    print(\"Could not get response.text()\")\n",
    "            return json.dumps({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919ff4c",
   "metadata": {},
   "source": [
    "Finally, we create a simple agent and run it with a user question. The agent uses your Azure OpenAI model for reasoning and the Azure AI Search tool for retrieval. It follows the given instructions to stay factual and cite sources. \n",
    "\n",
    "When you run the cell, you should see a grounded response based on the indexed documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the search tool for the agent providing the search client\n",
    "tools = AzureAISearchTool(search_client=search_client)\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    Assistant helps with questions on light technology and lighting systems. Be brief in your answers.\n",
    "    Answer ONLY with the facts listed in the sources you retrieve.\n",
    "    If there isn't enough information, say you don't know. Do not generate answers that don't use the retrieved sources.\n",
    "    Include source references for each fact you use using square brackets.\"\"\",\n",
    "    \n",
    "    tools=[tools.search]\n",
    ")\n",
    "\n",
    "# Minimal run sample with a single question\n",
    "user_question = \"Can you tell me something about the impact of indoor lighting on human health?\"\n",
    "result = await agent.run(\n",
    "    user_question,\n",
    "    )\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
